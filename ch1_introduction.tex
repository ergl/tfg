\cleardoublepage
\chapter{Introduction}

\todo{
What problems does this introduce? -> Lack of consistency, difficult for programmers to reason about these models.

What's consistency? -> Programmers want easy to understand models, and transactions are useful.

Systems that offer strong consistency are usually slow, so we focus on a model between strong and weak consistency, and show that an implementation can achieve performance close to the offered by weak consistent systems, but without their limitations.

Mention previous work (NMSI), and how we differ from them (vector clocks vs dependence vectors)

Overview of what we're covering in the thesis: explanation of the model (PSI/NSMI), an implementation of the protocol, and a comparative evaluation. Link to the code on github.
}

The rise of ubiquitous, globally-available services on the Internet, paired with the ever-increasing amount of data being uploaded to these services, presents two problems: on the one hand, no one service can store all its data in a single computer; on the other hand, users expect that these services operate in a responsive and reliable manner. The solutions are \emph{distribution}, which involves dividing large amounts of data in \emph{shards} or \emph{partitions} among multiple computers; and \emph{replication}, which allows to place identical copies of data in multiple geographical regions. Modern cloud applications use a combination of the two: for example, a social media site might decide to partition its data by user location, and place them in geographical regions closest to these locations, so that users can access their data without incurring a high latency penalty. In addition, the site might replicate these partitions to other geographical regions to achieve fault-tolerance: no single faulty region can result in data being unavailable.

These approaches, however, add significant complexity to the design, implementation and usage of the databases that usually power cloud applications. The presence of multiple replicas raises the question of how to keep them \emph{consistent}, that is, reflecting an unified version of the data they contain. Traditional relational databases also implement \emph{transactions}, that allow application programmers to reason about their code as a set of \emph{isolated}, atomic operations on shared data. With partitioned databases, transactions might be \emph{distributed}, updating values in multiple partitions, and therefore requiring coordination between them so that changes are applied to the database in an atomic manner.
